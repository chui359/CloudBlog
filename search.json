[{"title":"在AWS的Multi-Agent Orchestrator中練習使用SupervisorAgent來實現同時處理多個用戶請求","url":"/blog/supervisoragent-handle-multiple-user-requests/","content":"前言為了理解相關Multi-Agent的運作邏輯，在這裡練習使用 Multi-Agent Orchestrator 框架來實現多代理協同處理用戶請求。\n運作邏輯初始化 Orchestrator初始化分類器的相關設定。\n# 創建一個多代理協同管理器 (orchestrator)orchestrator = MultiAgentOrchestrator(options=OrchestratorConfig(  LOG_AGENT_CHAT=True,                # 記錄代理聊天  LOG_CLASSIFIER_CHAT=True,           # 記錄分類器聊天  LOG_CLASSIFIER_RAW_OUTPUT=True,     # 記錄分類器的原始輸出  LOG_CLASSIFIER_OUTPUT=True,         # 記錄分類器輸出  LOG_EXECUTION_TIMES=True,           # 記錄執行時間  MAX_RETRIES=3,                      # 最大重試次數  USE_DEFAULT_AGENT_IF_NONE_IDENTIFIED=True, # 未識別代理時使用默認代理  MAX_MESSAGE_PAIRS_PER_AGENT=10      # 每個代理的最大消息對數))\n\n初始化代理這裡依照需求建立所需的代理，目前這裡以初始化技術代理 (Tech Agent) 和健康代理 (Health Agent)作為範例。\n# 初始化技術代理 (Tech Agent)tech_agent = BedrockLLMAgent(BedrockLLMAgentOptions(  name=&quot;Tech Agent&quot;,  description=&quot;Specializes in technology areas including software development, hardware, AI, \\  cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs \\  related to technology products and services.&quot;,))# 初始化健康代理 (Health Agent)health_agent = BedrockLLMAgent(BedrockLLMAgentOptions(  name=&quot;Health Agent&quot;,  description=&quot;Focuses on health and medical topics such as general wellness, nutrition, diseases, treatments, mental health, fitness, healthcare systems, and medical terminology or concepts.&quot;,))\n\n初始化 SupervisorAgent這裡創建了一個 SupervisorAgent，是用來作為協調技術代理和健康代理的管理者代理，並將它們添加到 Orchestrator以供分類器使用。\n備註：如果需要同時讓分類器選擇多筆agent，可以再加入其他agent進入Orchestrator。\n# 初始化管理者 (Supervisor Agent) supervisor = BedrockLLMAgent(BedrockLLMAgentOptions(    name=&quot;Team Lead&quot;,    streaming=True,    description=&quot;Coordinates specialized team members&quot;))# Create and add supervisor agentsupervisor_agent = SupervisorAgent(SupervisorAgentOptions(    lead_agent=supervisor,    team=[tech_agent, health_agent],    trace=True))orchestrator.add_agent(supervisor_agent)\n\n處理用戶請求定義一個異步函數 handle_request 用來處理用戶請求，並使用 Orchestrator 進行路由。\n# 處理用戶請求的異步函數async def handle_request(_orchestrator: MultiAgentOrchestrator, _user_input: str, _user_id: str, _session_id: str):    response: AgentResponse = await _orchestrator.route_request(_user_input, _user_id, _session_id)    # 顯示元數據    print(&quot;\\nMetadata:&quot;)    print(f&quot;Selected Agent: &#123;response.metadata.agent_name&#125;&quot;)    if response.streaming:        print(&#x27;Response:&#x27;, response.output.content[0][&#x27;text&#x27;])    else:        print(&#x27;Response:&#x27;, response.output.content[0][&#x27;text&#x27;])\n\n主函數最後，我們的主函數允許用戶輸入請求，並調用 handle_request 來處理這些請求。\nif __name__ == &quot;__main__&quot;:    USER_ID = &quot;user123&quot;    SESSION_ID = str(uuid.uuid4())    print(&quot;Welcome to the interactive Multi-Agent system. Type &#x27;quit&#x27; to exit.&quot;)    while True:        # 獲取用戶輸入        user_input = input(&quot;\\nYou: &quot;).strip()        if user_input.lower() == &#x27;quit&#x27;:            print(&quot;Exiting the program. Goodbye!&quot;)            sys.exit()        # 執行異步函數        asyncio.run(handle_request(orchestrator, user_input, USER_ID, SESSION_ID))\n\n程式運行流程\n用戶輸入問題。\nhandle_request 函數調用 Orchestrator 來路由請求。\nSupervisorAgent 協調 Tech Agent 和 Health Agent 同時處理請求。\n系統輸出合併的回應結果。\n\n這個設計能夠同時處理一個問句中包含的多個領域的問題。\n","categories":["AI"],"tags":["AWS","LLM","Python"]},{"title":"Minimal API 在不同環境中不同的錯誤處理狀況","url":"/blog/minimal-api-error-handling-in-different-environments/","content":"前言在開發程式的時候，我們經常會需要透過錯誤的攔截，來進行後續的處理，但是在不同的環境中（開發環境或生產環境），程式的運行行為可能會有所不同，這經常會影響到我們在處理錯誤和除錯時的狀況。在這篇文章中，我將說明我在 Minimal API 中在生產環境遇到沒有被攔截的錯誤處理。\n問題自訂Middleware我在透過Minimal API進行開發的時候，希望使用自訂的 HttpExceptionMiddleware 來攔截和處理所有在請求處理過程中發生的例外。這個 Middleware 的核心邏輯是在執行下一個委派 (_next(httpContext)) 時捕捉所有例外，並將這些例外傳遞給 HandleExceptionAsync 方法進行處理。\ncsharpCopy codepublic class HttpExceptionMiddleware&#123;    private readonly RequestDelegate _next;    public HttpExceptionMiddleware(RequestDelegate next)    &#123;        _next = next;    &#125;    public async Task Invoke(HttpContext httpContext)    &#123;        try        &#123;            await _next(httpContext);        &#125;        catch (Exception ex)        &#123;            await HandleExceptionAsync(httpContext, ex);        &#125;    &#125;    private Task HandleExceptionAsync(HttpContext context, Exception ex)    &#123;        var response = ApiExceptionHandler.HandleException&lt;object&gt;(ex);        context.Response.ContentType = &quot;application/json&quot;;        context.Response.StatusCode = response.Status;        return context.Response.WriteAsJsonAsync(response, new JsonSerializerOptions        &#123;            DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull        &#125;);    &#125;&#125;\n\n這個 Middleware 確保了即使在後續的處理邏輯中發生例外，也能統一返回格式化的錯誤訊息，且根據不同的例外情況設定相應的 HTTP 狀態碼。\n不同環境的攔截問題開發環境當參數綁定失敗時，會預期拋出 BadHttpRequestException，並返回 400 Bad Request 的狀態碼。同時，錯誤訊息會具體指出是哪個參數綁定失敗 “Failed to read parameter …”。\n\n生產環境而在生產環境中，當參數綁定失敗時，則只會返回 400 Bad Request 的狀態碼，並且不會拋出任何例外或詳細的錯誤訊息。\n\n經過測試後才發現，Minimal API原來會自己判斷環境是否在Development以使用不同的方式來處理這些錯誤。\n\n如何修正在 Minimal API 中，參數綁定錯誤的處理方式可以通過配置 RouteHandlerOptions.ThrowOnBadRequest 選項來控制，這個選項決定了當參數綁定失敗時是否應該拋出例外，在默認情況下，這個只會在開發環境中啟用。\n以下是設定範例：\nvar builder = WebApplication.CreateBuilder();builder.Services.Configure&lt;RouteHandlerOptions&gt;(options =&gt;&#123;    options.ThrowOnBadRequest = true;&#125;);var app = builder.Build();app.MapGet(&quot;/weatherforecast/&#123;id&#125;&quot;, (Guid id) =&gt;&#123;    return Results.Ok(id);&#125;);\n\n透過這種方式，即使在生產環境中，當參數綁定失敗時也會拋出例外，並且可以捕捉到詳細的錯誤訊息。\n重點整理\n在 Minimal API 中，參數綁定錯誤的處理方式會根據環境而異：開發環境會拋出詳細例外，而生產環境則僅返回 400 Bad Request。\n透過配置 RouteHandlerOptions.ThrowOnBadRequest，可以統一開發和生產環境的錯誤處理行為，讓生產環境也拋出例外。\n\n參考資料https://github.com/dotnet/aspnetcore/issues/48355\nRouteHandlerOptions.ThrowOnBadRequest Property (Microsoft.AspNetCore.Routing) | Microsoft Learn\n","categories":["C#"],"tags":["C#",".NET Framework","Minimal Api"]},{"title":"怎麼使用RAGAS？","url":"/blog/how-to-use-ragas/","content":"因為工作需求需要研究一下RAGAS，但是發現中文相關的資訊並不多，所以我主要參考了官方的文件，建立了一個簡單的python實作，並透過這個實作稍微簡單的介紹一下RAGAS是什麼。\n前言一般來說，對於RAG系統的評估通常會依賴於人工標註的真實數據，但這種方法耗時且成本高。為了應對這個狀況，出現 RAGAS（Retrieval Augmented Generation Assessment），這是一種不需要依賴人工標註的評估框架。RAGAS提供了一套衡量指標，可以用來評估RAG系統中的不同維度，從而實現更快速的評估循環。\n1. 語言模型的知識庫角色與局限性\n語言模型（LMs）能夠捕捉大量世界知識，回答問題無需訪問外部來源。\n大型語言模型（LLMs）在各種問題回答基準上表現出與人類相當的能力，但仍存在兩個基本限制：\n無法回答訓練之後發生的資訊。\n難以使用訓練資料中很少提及的知識。\n\n\n\n2. 檢索增強生成（RAG）的使用\nRAG通過從語料庫中檢索相關段落並將這些段落與原始問題一起輸送給LM來回答問題。\n初期方法依賴於專門的LMs進行檢索增強語言建模，但最近的研究表明，僅將檢索到的文檔添加到標準LM的輸入中也能達到良好效果，這使得在僅通過API獲取的LLMs中也能使用檢索增強策略。\n\n3. RAG系統實施的挑戰\nRAG策略的有效性已經顯而易見，但其實施需要大量調整，因為整體性能會受到檢索模型、考慮的語料庫、LM和提示格式等多方面的影響。\n自動化評估RAG系統至關重要，傳統上，RAG系統常通過語言建模任務本身（例如測量參考語料上的困惑度）來評估，但這些評估不能預測結果的效果。\n\n4. RAGAS框架的引入\nRAGAS是一個自動評估檢索增強生成系統的框架，專注於無需參考答案的設置，並估算正確性和檢索段落的有用性等不同代理指標。\nRAGAS與llamaindex和Langchain集成，這兩者是構建RAG解決方案中最廣泛使用的框架，使得開發者能夠輕鬆將RAGAS整合到他們的標準工作流程中。\n\n評估策略1. RAGAS設置\n問題 ( q ) 給出後，系統首先檢索相關上下文 ( c(q) )，然後使用檢索到的上下文生成答案 ( as(q) )。    RAG Setting for RAGAS\n\n問題建立\n\n\ndata_samples = &#123;    &#x27;question&#x27;: [&#x27;When was the first super bowl?&#x27;, &#x27;Who won the most super bowls?&#x27;],    &#x27;answer&#x27;: [&#x27;The first superbowl was held on Jan 15, 1967&#x27;, &#x27;The most super bowls have been won by The New England Patriots&#x27;],    &#x27;contexts&#x27; : [[&#x27;The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,&#x27;],    [&#x27;The Green Bay Packers...Green Bay, Wisconsin.&#x27;,&#x27;The Packers compete...Football Conference&#x27;]],&#125;custom_dataset = Dataset.from_dict(data_samples)\n\n\n透過langchain導入模型，我是使用azure建立語言模型，各位可以依照自己的需求建立\n\nfrom langchain_openai import AzureChatOpenAIfrom langchain_openai import AzureOpenAIEmbeddingsfrom ragas.llms import LangchainLLMWrapperfrom ragas import evaluateazure_model = AzureChatOpenAI(    azure_deployment=&quot;gpt4o&quot;,    azure_endpoint = RESOURCE_ENDPOINT,    openai_api_type=&quot;azure&quot;,    openai_api_key = API_KEY,    api_version=&quot;2024-02-15-preview&quot;,     max_tokens=2048,)ragas_azure_model = LangchainLLMWrapper(azure_model)azure_embeddings = AzureOpenAIEmbeddings(    deployment=&quot;text-embedding-ada-002&quot;,    model=&quot;text-embedding-ada-002&quot;,    azure_endpoint = RESOURCE_ENDPOINT,    openai_api_type=&quot;azure&quot;,    openai_api_key = API_KEY,)\n\n2. 範例指標\n真實性（Faithfulness）：答案應該以給定上下文為基礎，避免幻覺，確保檢索到的上下文能作為生成答案的依據。\n答案相關性（Answer Relevance）：生成的答案應該直接回應給定的問題。\n\n# Patch Metrics with Azure Modelfrom ragas.metrics import (faithfulness, answer_relevancy)metrics = [faithfulness, answer_relevancy]# Evaluateresult = evaluate(    custom_dataset, metrics=metrics, llm=ragas_azure_model, embeddings=azure_embeddings)df = result.to_pandas()print(df)\n\n評估工具1. 真實性測量(Faithfulness Score)\n用於衡量產生答案和contexts對比的事實準確度。是指答案中的聲明是否可以從上下文中推斷出來。    \n\n|V| &#x3D; LLM 支援的語句數量，|S| &#x3D; 語句總數。\n  範例  \n\n\n2. 答案相關性測量(Answer Relevance Score)\n評估產生答案與問題的關聯程度。    \n\n使用text-embedding-ada-002模型獲取所有問題的嵌入，並計算原始問題 ( q ) 與生成問題 ( qi ) 的相似度 ( sim(q, qi) ) 。\n\n該指標評估生成答案與最初問題或指令的對齊程度。\n  範例  \n\n\n重點整理1. 自動化無參考資料評估\n主要的目的是建立一個自動化且無需參考資料的RAG系統評估。\n\n2. RAGAS框架\n描述了RAGAS框架及其實施。\n該框架易於使用，即使在沒有任何真實數據的情況下，也能為RAG系統開發者提供有價值的見解。\n\n參考資料https://arxiv.org/abs/2309.15217\nhttps://docs.ragas.io/en/latest/concepts/metrics/index.html\nhttps://baoyu.io/translations/rag/evaluating-rag-applications-with-ragas\nhttps://bajpaihimanshu.medium.com/papermadeeasy-ragas-automated-evaluation-of-retrieval-augmented-generation-ccfe5ea50db0\nhttps://idataagent.com/2024/05/27/mastering-rag-assessment-skills-from-beginner-to-expert/\n","categories":["AI"],"tags":["LLM","RAG","Python"]},{"title":"使用 argparse 建構 Python CLI 工具的核心運作邏輯","url":"/blog/cmeaqvcyf0009b8lcbfiv7vqm/","content":"前言隨著自動化與工具化需求增加，命令列工具（CLI）在程式開發中扮演重要角色。Python 的 argparse 模組提供靈活且強大的參數解析能力，讓開發者能夠快速建構可擴充且易維護的 CLI 應用。本文將以 HTML 轉 Markdown 工具為例，整理 argparse 的主要架構與運作邏輯，幫助讀者掌握命令解析的核心知識。\n運作邏輯初始化 OrchestratorOrchestrator（主解析器）負責統籌所有命令列參數的解析，並建立 CLI 工具的主架構。\nimport argparseparser = argparse.ArgumentParser(description=&quot;RAG System CLI&quot;)\n\nArgumentParser 物件是所有參數解析行為的核心。\ndescription 用於提供工具全域描述，顯示於 help 訊息。\n\n初始化代理代理（subparsers）負責各自命令的參數解析，能夠區分並處理不同功能模塊。\nsubparsers = parser.add_subparsers(dest=&#x27;command&#x27;, help=&#x27;Available commands&#x27;)convert_parser = subparsers.add_parser(&#x27;convert&#x27;, help=&#x27;Convert HTML file(s) to Markdown format&#x27;)convert_parser.add_argument(&#x27;input_path&#x27;, help=&#x27;Path to HTML file or directory containing HTML files&#x27;)convert_parser.add_argument(&#x27;-o&#x27;, &#x27;--output-dir&#x27;, default=&#x27;output&#x27;, help=&#x27;Output directory for Markdown files (default: output)&#x27;)convert_parser.add_argument(&#x27;-f&#x27;, &#x27;--filename&#x27;, help=&#x27;Custom output filename (for single file conversion only)&#x27;)convert_parser.add_argument(&#x27;-p&#x27;, &#x27;--pattern&#x27;, default=&#x27;*.html&#x27;, help=&#x27;File pattern for directory conversion (default: *.html)&#x27;)convert_parser.add_argument(&#x27;--content-filter&#x27;, choices=[&#x27;none&#x27;, &#x27;pruning&#x27;, &#x27;bm25&#x27;], default=&#x27;none&#x27;, help=&#x27;內容過濾器類型（預設：none）&#x27;)convert_parser.add_argument(&#x27;-q&#x27;, &#x27;--query&#x27;, help=&#x27;用戶查詢字串，用於內容過濾（適用於 BM25 過濾器）&#x27;)convert_parser.add_argument(&#x27;--pruning-threshold&#x27;, type=float, default=0.3, help=&#x27;設定Pruning過濾器的閾值（預設值：0.3，較小值會保留更多內容）&#x27;)convert_parser.set_defaults(func=convert_html_command)\n\n各代理解析器（如 convert_parser）專責特定命令的參數。\n可針對功能需求自由擴充多個命令解析器。\n\n初始化 SupervisorAgent在此架構下，SupervisorAgent可視為管理指令執行的調度者，負責依命令類型呼叫對應函式。\n# 於argparse中，SupervisorAgent可理解為由set_defaults設定的函式convert_parser.set_defaults(func=convert_html_command)\n\n透過 set_defaults(func=...) 將命令與處理函式綁定，確保後續能自動調用。\n\n處理用戶請求用戶請求被主解析器解析後，會自動分派至對應命令的處理函式。\nargs = parser.parse_args()if not args.command:    parser.print_help()    return# 呼叫與命令綁定的函式args.func(args)\n\nparse_args() 解析整體命令列參數（包含主命令與子命令）。\n依據 args.command 判斷是否有指定子命令，否則僅顯示說明。\n由 args.func(args) 依解析結果執行專屬處理邏輯。\n\n主函數主程式作為 CLI 工具入口，負責啟動解析流程並處理互動。\ndef main():    &quot;&quot;&quot;Main CLI entry point.&quot;&quot;&quot;    parser = argparse.ArgumentParser(description=&quot;RAG System CLI&quot;)    subparsers = parser.add_subparsers(dest=&#x27;command&#x27;, help=&#x27;Available commands&#x27;)    # ...（此處省略子命令設定）    args = parser.parse_args()    if not args.command:        parser.print_help()        return    args.func(args)\n\n將所有初始化、代理配置整合於主函數，確保工具能正確運作。\n\n程式運行流程\n建立主解析器（Orchestrator）初始化 ArgumentParser，設定全域說明。\n\n新增代理（命令解析器）透過 add_subparsers 與 add_parser 定義各命令及其參數。\n\n綁定處理函式（SupervisorAgent）使用 set_defaults，將命令綁定至對應的處理函式。\n\n解析與分派用戶請求使用 parse_args() 解析參數，並由 args.func(args) 執行命令。\n\n\n\n備註：\n\n對於多命令、多功能需求，可於「初始化代理」區段增添更多解析器。\n可根據業務需要，於處理函數實作錯誤管理、輸出格式化等進階功能。\n所有程式碼皆可直接複製並於 Python3 環境執行。\n\n\n","categories":["Python"],"tags":["Python","argparse","CLI"]},{"title":"如何建立 GPT Function Call","url":"/blog/how-to-create-gpt-function-call/","content":"前言在本篇文章中，我將介紹如何建立一個 GPT function call，並結合 Azure OpenAI 服務來進行內容過濾的應用。\n建立 API 端點首先，我們需要建立一個簡單的 API 端點，該端點將接收使用者的輸入並使用 GPT 服務來進行內容過濾。以下是範例程式碼：\napp.MapPost(&quot;/userContentFilter&quot;, async ([FromBody] ExtractKeywordsRequest request, [FromServices] GPTService gptService) =&gt;&#123;    return await gptService.UserContentFilter(request.UserInput, request.GptVersion, request.Temperature);&#125;);\n\n這段程式碼中，我們定義了一個 /userContentFilter 的 POST API 端點，該端點將接收使用者的輸入並傳遞給 GPTService 進行處理。\nGPT 服務的實作接下來，我們來看一下 UserContentFilter 方法的實作。這個方法負責將使用者的問題傳遞給 GPT 模型進行處理，並根據 GPT 的回應決定是否需要對使用者的問題進行修改。\npublic async Task&lt;UserContentFilterResponse&gt; UserContentFilter(string questions, string gptVersion, float temperature = 0)&#123;    List&lt;LogResponse&gt; logs = new List&lt;LogResponse&gt;();    var content = new    &#123;        temperature,        max_tokens = 1000,        top_p = 1.0,        messages = new List&lt;dynamic&gt;        &#123;            new            &#123;                role = &quot;system&quot;,                content = &quot;You are responsible for reviewing user statements as a content filter. &quot; +                &quot;Please check for inappropriate content such as &#x27;hate&#x27;, &#x27;self_harm&#x27;, &#x27;violence&#x27;, etc.&quot;            &#125;,            new            &#123;                role = &quot;user&quot;,                content = questions            &#125;        &#125;,        tools = new List&lt;dynamic&gt;        &#123;            new            &#123;                type = &quot;function&quot;,                function = new                &#123;                    name = &quot;userContentFilter&quot;,                    parameters = new                    &#123;                        type = &quot;object&quot;,                        properties = new                        &#123;                            type = new                            &#123;                                type = &quot;string&quot;,                                @enum = new List&lt;string&gt; &#123; &quot;modify_response&quot;, &quot;hate&quot;, &quot;jailbreak&quot;, &quot;self_harm&quot;, &quot;sexual&quot;, &quot;violence&quot;, &quot;sql_injection&quot;, &quot;prompt_injection&quot; &#125;,                                description = &quot;Classify the content if any inappropriate type is detected.&quot;                            &#125;,                            rephraseUserQuestion = new                            &#123;                                description = &quot;Rephrase the user&#x27;s question if any inappropriate content is found. Otherwise, keep the original.&quot;,                                type = &quot;string&quot;                            &#125;,                            incorrectQuestion = new                            &#123;                                type = &quot;boolean&quot;,                                description = &quot;Indicate whether any inappropriate content was detected.&quot;,                            &#125;                        &#125;,                        required = new[] &#123; &quot;rephraseUserQuestion&quot;, &quot;incorrectQuestion&quot; &#125;                    &#125;                &#125;            &#125;        &#125;,        tool_choice = new        &#123;            type = &quot;function&quot;,            function = new            &#123;                name = &quot;userContentFilter&quot;            &#125;        &#125;    &#125;;    UserContentFilterData userContentFilterData = new();    try    &#123;        string gptResponse = await FormatGPTResponse(Function.JsonSerialize(content), gptVersion);        if (gptResponse == &quot;content_filter&quot;)        &#123;            userContentFilterData.Type = &quot;openai-content-filter&quot;;            userContentFilterData.RephraseUserQuestion = &quot;I want to inquire about the product.&quot;;            userContentFilterData.IncorrectQuestion = true;        &#125;        else        &#123;            var extractResponse = GPTFunction.GetToolChoiceContent(gptResponse);            userContentFilterData = JsonSerializer.Deserialize&lt;UserContentFilterData&gt;(extractResponse);        &#125;    &#125;    catch (Exception e)    &#123;        return new UserContentFilterResponse        &#123;            Status = &quot;fail&quot;,            TranslationKey = &quot;internal-server-error&quot;,            ErrorMessage = &quot;internal-server-error&quot;,            Logs = new List&lt;LogResponse&gt;            &#123;                new LogResponse                &#123;                    FunctionName = &quot;userContentFilter&quot;,                    Message = e.Message                &#125;            &#125;        &#125;;    &#125;    logs.Add(new LogResponse    &#123;        FunctionName = &quot;gpt-retrieveV2&quot;,        Message = new        &#123;            RetrieveProductData = userContentFilterData        &#125;,    &#125;);    return new UserContentFilterResponse    &#123;        Status = &quot;success&quot;,        TranslationKey = &quot;&quot;,        Type = userContentFilterData.Type,        IncorrectQuestion = userContentFilterData.IncorrectQuestion,        RephraseUserQuestion = userContentFilterData.RephraseUserQuestion,        OriginQuestion = questions,        Logs = logs    &#125;;&#125;\n\n說明\nMessages 定義：這部分程式碼設置了 GPT 會話的背景資訊，包括系統角色和使用者輸入。系統角色告知 GPT 它的角色是內容過濾器，並提供具體的過濾規則。\n例外處理：在捕獲到錯誤時，我們會記錄錯誤資訊並回傳一個失敗的回應，這有助於除錯和追蹤問題。\n\n其他輔助方法解析 GPT 回應GetToolChoiceContent 方法負責從 GPT 的回應中提取具體的工具選擇內容。\npublic static string GetToolChoiceContent(string jsonData)&#123;    JsonDocument jsonDoc = JsonDocument.Parse(jsonData);    if (jsonDoc.RootElement.TryGetProperty(&quot;choices&quot;, out JsonElement choices) &amp;&amp; choices.GetArrayLength() &gt; 0)    &#123;        JsonElement firstChoice = choices[0];        if (firstChoice.TryGetProperty(&quot;message&quot;, out JsonElement message))        &#123;            if (message.TryGetProperty(&quot;tool_calls&quot;, out JsonElement toolCalls) &amp;&amp; toolCalls.GetArrayLength() &gt; 0)            &#123;                JsonElement firstToolCall = toolCalls[0];                if (firstToolCall.TryGetProperty(&quot;function&quot;, out JsonElement function))                &#123;                    if (function.TryGetProperty(&quot;arguments&quot;, out JsonElement arguments))                    &#123;                        return arguments.GetString();                    &#125;                &#125;            &#125;        &#125;    &#125;    return string.Empty;&#125;\n\n呼叫 GPT 服務在 FormatGPTResponse 方法中，我們將使用者的輸入轉換為 JSON 格式，並呼叫 GPT 服務來取得回應。\nprivate async Task&lt;string&gt; FormatGPTResponse(string content, string GPTVersion = &quot;&quot;)&#123;    if (string.IsNullOrEmpty(GPTVersion))    &#123;        GPTVersion = &quot;gpt-4&quot;;    &#125;    var urlObject = await GetOrSetCache(GPTVersion);    try    &#123;        return await _azureAIService.CallGPTAsync(content, urlObject.Result.Uri, urlObject.Result.ApiKey);    &#125;    catch    &#123;        throw;    &#125;&#125;","categories":["GPT-technology"],"tags":["LLM","C#",".NET Framework"]},{"title":"透過JsonSerializerOptions排除回傳 null 值的方法","url":"/blog/exclude-null-values-with-jsonserializeroptions/","content":"前言在某次System.Text.Json上的開發需求中，我遇到當資料中包含 null 值時，要排除 null 值的需求，主要是希望能夠減少不必要的資訊量，讓回應比較簡潔。而在 .NET 中，使用 JsonSerializerOptions 可以輕鬆完成這件事情。\n如何運作以下我使用Middleware中的HandleException作為範例：\nprivate Task HandleExceptionAsync(HttpContext context, Exception ex)&#123;    var response = ApiExceptionHandler.HandleException&lt;object&gt;(ex);    context.Response.ContentType = &quot;application/json&quot;;    context.Response.StatusCode = response.Status;    return context.Response.WriteAsJsonAsync(response, new JsonSerializerOptions    &#123;        DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull    &#125;);&#125;\n\n\nWriteAsJsonAsync 會自動將傳遞給它的物件轉換為 JSON 格式。\nJsonSerializerOptions 是 .NET 中用於控制 JSON 序列化和反序列化行為的配置選項，在這裡，你還可以自定義 JSON 的序列化過程，包括屬性名稱的格式、 null 值處理等。\nDefaultIgnoreCondition：這個選項用來指定在序列化過程中應該忽略哪些屬性。例如，在這裡可以設置為 JsonIgnoreCondition.WhenWritingNull 讓屬性的值為 null 時，該屬性將不會被包含在 JSON 輸出中。\n\n範例測試\n觸發一個 BadHttpRequestException 或其他錯誤，確保 Result 被設置為 null。\n\n如果設置正確，則結果應該如預期不顯示 null 的 Result。\n&#123;    &quot;status&quot;: 400,    &quot;message&quot;: &quot;Bad Request - Invalid JSON format.&quot;&#125;\n\n而不是：\n&#123;    &quot;status&quot;: 400,    &quot;message&quot;: &quot;Bad Request - Invalid JSON format.&quot;,    &quot;result&quot;: null&#125;\n\n重點整理這裡簡單的介紹了在 .NET 中如何使用 JsonSerializerOptions 來排除回應中的 null 值。如果你需要在開發過程中實現類似功能，這種方法能有效提升 API 的效率與簡潔度。\n參考資料json.net - Ignore property when null using the new Net Core 3.0 Json - Stack Overflow\n如何使用 System.Text.Json 忽略屬性 - .NET | Microsoft Learn\n","categories":["C#"],"tags":["C#",".NET Framework"]},{"title":"Hexo 常用指令整理","url":"/blog/hexo-common-commands-summary/","content":"整理一些我自己常用的Hexo相關指令。\n建立新文章$ hexo new &quot;My New Post&quot;\n\n本機執行伺服器$ hexo server\n\n生成靜態文件並部署到遠程站點$ hexo generate --deploy\n\n更多資訊請參考：Deployment\n","categories":["Hexo"],"tags":["Hexo"]},{"title":"在 pytest 使用假資料進行 API 測試","url":"/blog/cmearc1wz0000c0lcgij2fijp/","content":"前言本篇文章的背景是針對使用 pytest 進行 API 測試時，為什麼我們常常會使用「假資料（mock）」而不是直接呼叫後端。動機是許多初學者在撰寫單元測試時，會直接打後端 API，結果導致測試不穩定、速度慢、容易出現不必要的錯誤。主要目標是透過範例與解說，幫助讀者理解：\n\npytest 的用途與測試目的。\n為什麼要用假資料取代真實後端呼叫。\n如何用 patch 來控制測試結果，讓測試快速且穩定。\n\n運作邏輯測試初始化在這個案例中，我們使用 pytest 搭配 pytest-asyncio 來測試一個 FastAPI API。這個 API /project 會透過 backend_api_projects 去呼叫後端服務，我們會用 unittest.mock.patch 將它替換成假資料，避免真正連線後端。\nimport pytestfrom unittest.mock import patch@pytest.mark.asyncioasync def test\\_list\\_projects\\_success(async\\_client):mock\\_response = &#123;&quot;result&quot;: \\[&#123;&quot;projectId&quot;: 1, &quot;projectName&quot;: &quot;Test Project&quot;&#125;,&#123;&quot;projectId&quot;: 2, &quot;projectName&quot;: &quot;Another Project&quot;&#125;]&#125;with patch(&quot;app.services.project_service.backend_api_projects&quot;, return_value=mock_response):    response = await async_client.get(&quot;/project&quot;)assert response.status_code == 200data = response.json()assert data[&quot;status&quot;] == 200assert len(data[&quot;result&quot;][&quot;projectList&quot;]) == 2\n\n為什麼要用假資料（mock）\n專注測試自己的邏輯不受外部系統（後端、資料庫、網路）影響，測試失敗時能快速定位是自己程式的問題還是外部因素。\n\n資料一致性後端資料可能每天都變動，直接呼叫可能導致今天測試通過、明天失敗，假資料能保證每次測試的輸入一致。\n\n速度快呼叫真實後端可能需要數百毫秒甚至數秒，假資料幾乎是瞬間回傳。\n\n模擬錯誤情境很多情況（如後端回傳 500、回傳空清單）在真實系統中難以控制，mock 可以直接製造這些情境來測試。\n\n\n\npatch 的運作原理patch 會在測試期間，暫時替換掉指定位置的函式或物件，讓它回傳我們指定的內容。一旦測試結束，替換會自動還原，不影響原本程式。\nwith patch(&quot;模組路徑.函式名稱&quot;, return\\_value=假資料):\\# 測試程式在這裡執行時，呼叫的就是假資料\n\n\n測試流程\n準備假資料建立一個模擬後端回傳的 JSON。\n\n使用 patch 替換函式將 backend_api_projects 改成直接回傳假資料。\n\n發送 API 請求用測試用的 async_client 呼叫 /project。\n\n驗證結果確認回傳的 HTTP 狀態碼與資料筆數符合預期。\n\n\n\n範例流程圖測試程式│├── patch backend\\_api\\_projects → 假資料│├── 呼叫 /project API│├── 執行 API 邏輯（使用假資料）│└── 驗證回傳內容是否符合預期\n\n\n完整測試範例import pytestfrom unittest.mock import patch@pytest.mark.asyncioasync def test\\_list\\_projects\\_success(async\\_client):\\# 1. 準備假資料mock\\_response = &#123;&quot;result&quot;: \\[&#123;&quot;projectId&quot;: 1, &quot;projectName&quot;: &quot;Test Project&quot;&#125;,&#123;&quot;projectId&quot;: 2, &quot;projectName&quot;: &quot;Another Project&quot;&#125;]&#125;# 2. 使用 patch 替換 backend_api_projectswith patch(&quot;app.services.project_service.backend_api_projects&quot;, return_value=mock_response):    # 3. 呼叫 API    response = await async_client.get(&quot;/project&quot;)# 4. 驗證結果assert response.status_code == 200data = response.json()assert data[&quot;status&quot;] == 200assert len(data[&quot;result&quot;][&quot;projectList&quot;]) == 2\n\n\n備註  \n\n單元測試（unit test）建議使用假資料，讓測試獨立且穩定。  \n如果要測試與真實後端的整合，則屬於整合測試（integration test）或 E2E 測試，這種測試會使用真實環境，但速度較慢、受外部影響大。\n\n\n","categories":["Python"],"tags":["Python","pytest"]},{"title":"解決 Kubernetes Service 注入環境變數導致程式錯誤問題","url":"/blog/cmel47ih200000clc26nu7kb7/","content":"前言在 Kubernetes 上部署應用程式時，經常會利用 Service 來提供 Pod 之間的服務存取。但在實際應用中，Kubernetes 會自動將 Service 的資訊以環境變數的形式注入到 Pod 內部，這有時候會與應用程式原本預期的環境變數設計衝突，導致應用無法正常啟動。  \n本文以一次在 EKS 上部署 RabbitMQ Client（crawler app） 的真實案例，整理如何排查與修復由 自動注入的 Service 環境變數 所造成的錯誤。\n\n問題應用程式在 EKS 中部署後，Pod 出現以下錯誤：\nValueError: invalid literal for int() with base 10: &#x27;tcp://&lt;CLUSTER-IP&gt;:5672&#x27;````程式碼片段：```pythonrabbitmq_port: int = int(os.getenv(&quot;RABBITMQ_PORT&quot;, 5672))\n\n期望值：RABBITMQ_PORT=5672\n實際值（容器內檢查）：\nkubectl exec -it deployment/crawler -n &lt;namespace&gt; -- env | grep RABBITRABBITMQ_PORT=tcp://&lt;CLUSTER-IP&gt;:5672RABBITMQ_SERVICE_HOST=&lt;CLUSTER-IP&gt;RABBITMQ_SERVICE_PORT=5672...\n\n問題原因：Kubernetes 會依照 Service 名稱，自動注入一系列環境變數，例如 RABBITMQ_PORT、RABBITMQ_SERVICE_HOST、RABBITMQ_SERVICE_PORT。其中 RABBITMQ_PORT 的格式是 URI（如 tcp://&lt;IP&gt;:&lt;PORT&gt;），導致程式在 int() 轉換時失敗。\n\n解決辦法這個問題可以有多種修復策略，以下列出三種常見的解法：\n方案一：覆蓋環境變數在 Deployment &#x2F; Helm chart 中顯式定義 RABBITMQ_PORT，覆蓋掉 Kubernetes 自動注入的值：\nenv:  - name: RABBITMQ_HOST    value: &quot;rabbitmq&quot;  - name: RABBITMQ_PORT    value: &quot;5672&quot;\n\n這樣保證程式拿到的永遠是數字型態的 port。\n\n方案二：程式調整避免直接讀取 RABBITMQ_PORT，改為使用 K8s 自動注入的 RABBITMQ_SERVICE_HOST 與 RABBITMQ_SERVICE_PORT：\nrabbitmq_host = os.getenv(&quot;RABBITMQ_SERVICE_HOST&quot;, &quot;localhost&quot;)rabbitmq_port = int(os.getenv(&quot;RABBITMQ_SERVICE_PORT&quot;, 5672))\n\n這樣不僅避免轉型錯誤，也更符合 Kubernetes 的設計模式。\n\n方案三：關閉 Service Links如果你完全不希望 Pod 自動注入 Service 環境變數，可以在 Deployment 規格中加上：\nspec:  template:    spec:      enableServiceLinks: false\n\n此設定會關閉 Service Links，讓 Pod 內不會再出現類似 RABBITMQ_PORT 的變數，環境變數管理會更乾淨。\n\n備註\nKubernetes 預設會依照 Service 名稱注入 &#123;SVCNAME&#125;_SERVICE_HOST、&#123;SVCNAME&#125;_SERVICE_PORT 與 &#123;SVCNAME&#125;_PORT 等變數，這是設計行為，不是 Bug。\n如果應用程式需要更高的可攜性，建議改為使用 DNS Service Discovery（例如 rabbitmq.&lt;namespace&gt;.svc.cluster.local:5672）而非環境變數。\n在多個 Service 共存的情境下，enableServiceLinks: false 可以有效避免命名衝突與環境污染。\n\n\n結論這次的問題核心在於 Kubernetes 預設行為與應用程式預期不一致。當 Pod 因為 Service 自動注入的環境變數導致程式崩潰時，可以透過：\n\n覆蓋環境變數（最簡單），\n修改程式邏輯（最佳實踐），\n關閉 Service Links（徹底乾淨），\n\n三種方式進行修正。\n這是一個很典型的 DevOps 跨層問題，未來如果遇到類似狀況，可以快速從「容器內環境變數」檢查起手，迅速定位根因。\n參考文獻https://kubernetes.io/docs/concepts/services-networking/service/#environment-variables\n","categories":["DevOps","Kubernetes"],"tags":["Kubernetes","EKS","Helm","Debug","RabbitMQ"]},{"title":"PostgreSQL ENUM 型別與資料表建置常見錯誤與解決方法整理","url":"/blog/cmemgequ900003clcdvm4aopv/","content":"前言在後端開發中，使用 ORM（如 SQLAlchemy）設計具備 Enum 型別的資料表是一種常見做法，尤其在任務管理、自訂狀態流程等場景中相當實用。然而，當將此設計實際部署到 PostgreSQL 資料庫時，若未正確建置 ENUM 型別，經常會遇到各種型別或預設值相關錯誤。本篇文章整理了我在建置 task 及 result 資料表時，所遇到的 PostgreSQL ENUM 型別相關問題，並歸納出最有效的解決辦法，提供給有相同需求的開發者參考。\n問題\n未建立 ENUM 型別導致插入失敗\n\n當 ORM 內 status 欄位設為 Enum，但 PostgreSQL 尚未建立對應 ENUM 型別，執行插入或建表時出現如下錯誤：ERROR:  type &quot;taskstatus&quot; does not exist\n\n\n修改欄位型別時預設值衝突\n\n當嘗試將既有欄位型別從 VARCHAR 轉為 ENUM 型別時，若欄位有預設值，會出現如下錯誤：ERROR:  default for column &quot;status&quot; cannot be cast automatically to type taskstatus\n\n\n\n解決辦法1. 建立 ENUM 型別在建立資料表前，必須先建立 ENUM 型別（以 taskstatus 為例，並補齊所有狀態值）：\nCREATE TYPE taskstatus AS ENUM (&#x27;PENDING&#x27;, &#x27;RUNNING&#x27;, &#x27;SUCCESS&#x27;, &#x27;FAILED&#x27;);\n\n2. 建立資料表正確使用 ENUM 型別於資料表 schema：\nCREATE TABLE task (    id UUID PRIMARY KEY,    url TEXT NOT NULL,    status taskstatus NOT NULL DEFAULT &#x27;PENDING&#x27;,    created_at TIMESTAMP NOT NULL DEFAULT NOW(),    started_at TIMESTAMP NULL,    finished_at TIMESTAMP NULL);CREATE TABLE result (    id UUID PRIMARY KEY,    task_id UUID NOT NULL,    url TEXT NOT NULL,    s3_path TEXT NULL,    CONSTRAINT fk_task FOREIGN KEY(task_id) REFERENCES task(id));COMMENT ON COLUMN result.s3_path IS &#x27;s3 path where to store the raw HTML&#x27;;\n\n3. 既有欄位型別轉換（含預設值）若需將既有資料表 status 欄位型別由 VARCHAR 轉為 ENUM，請依以下步驟操作：\n-- 1. 移除預設值ALTER TABLE task ALTER COLUMN status DROP DEFAULT;-- 2. 修改型別ALTER TABLE task ALTER COLUMN status TYPE taskstatus USING status::text::taskstatus;-- 3. 重新設定預設值ALTER TABLE task ALTER COLUMN status SET DEFAULT &#x27;PENDING&#x27;;\n\n4. 補充：加速查詢建議如有頻繁查詢需求，可針對關鍵欄位建立索引：\nCREATE INDEX idx_result_task_id ON result(task_id);CREATE INDEX idx_task_url ON task(url);\n\n\n備註：  \n\n若使用 migration 工具（如 Alembic），建議將 ENUM 型別建立、資料表建置及型別轉換操作，納入 migration script，確保多人協作及環境一致性。\n若有更多狀態或其他自訂 ENUM 型別需求，請先完整列出所有 Enum 欄位可能值，避免日後資料衝突。\n若遇到其他型別轉換相關錯誤，建議優先檢查預設值與現有資料型別是否相容。\n\n\n","categories":["PostgreSQL","資料庫管理"],"tags":["PostgreSQL","ENUM"]},{"title":"如何重置在 Amazon EKS 上部署的 RabbitMQ 叢集","url":"/blog/cmes4r8s60000j8lch35g7zwe/","content":"前言隨著企業對高可用與可擴展訊息佇列服務的需求增加，RabbitMQ 在 Kubernetes（特別是 Amazon EKS）上的部署愈發普及。然而，當叢集運行一段時間後，難免會遇到需要重啟或重置 RabbitMQ 叢集的情境，例如配置更新、節點異常等。本文將說明在 Amazon EKS 上，如何安全且有效地重置 RabbitMQ 叢集，並提供相應操作步驟與程式碼範例，協助維運人員快速處理相關問題。\n問題當 RabbitMQ 叢集出現下列狀況時，可能需要進行重置或重啟操作：\n\nRabbitMQ 節點出現異常或資料損壞\n部分設定需重新載入\n叢集需要釋放資源或解決暫時性問題\n\n針對不同需求，我們可以選擇「滾動重啟整個叢集」或「個別節點重置」兩種方式。\n解決辦法1. 滾動重啟 RabbitMQ Pods（建議做法）若僅需重新載入設定或解決小型問題，推薦採用 StatefulSet 的滾動重啟。此方式可最小化服務中斷，逐一重啟每個 Pod。\n操作步驟\n執行以下指令，重啟 RabbitMQ 的 StatefulSet：\n kubectl rollout restart statefulset &lt;your-rabbitmq-statefulset-name&gt; -n &lt;your-namespace&gt;\n\n請將 &lt;your-rabbitmq-statefulset-name&gt; 替換成實際的 StatefulSet 名稱。\n&lt;your-namespace&gt; 則為 RabbitMQ 部署於 Kubernetes 的命名空間。\n\n\n等待所有 Pod 依序重啟完成。\n\n\n\n注意事項：\n\n滾動重啟會保留節點資料與叢集狀態，僅重新啟動應用服務，風險低且建議優先採用。\n\n\n\n2. 重置單一 RabbitMQ 節點（較嚴重情境）若某個 RabbitMQ 節點嚴重異常或需清除資料庫時，可手動進行節點重置。此操作將移除該節點內部資料，請務必確認是否有備份，並評估對叢集的影響。\n操作步驟\n進入欲重置的 RabbitMQ Pod：\n kubectl exec -it &lt;your-rabbitmq-pod-name&gt; -n &lt;your-namespace&gt; -- bash\n\n停止 RabbitMQ 應用：\n rabbitmqctl stop_app\n\n執行重置指令（兩種選擇）：\n 一般重置（移除資料，但維持叢集與使用者資訊）：\n rabbitmqctl reset\n 強制重置（更徹底移除）：\n rabbitmqctl force_reset\n\n重新啟動 RabbitMQ 應用：\n rabbitmqctl start_app\n\n離開 Pod：\n exit\n\n\n注意事項：\n\nrabbitmqctl reset 或 force_reset 會移除該節點的資料庫，適用於資料損壞或需要重建節點時。\n重置操作前，請確認叢集其他節點皆健康，避免叢集狀態異常。\n\n\n\n3. 使用 RabbitMQ Cluster Kubernetes Operator（進階場景）若叢集是透過 RabbitMQ Cluster Kubernetes Operator 管理，建議依照官方文件操作，因 Operator 會自動管理節點生命週期，直接手動重置可能導致不一致狀態。\n結論在 Amazon EKS 上管理 RabbitMQ 叢集時，根據實際需求選擇適合的重置方式至關重要。滾動重啟適合日常維運與輕微問題，節點重置則適用於重大異常修復。維運人員應熟悉上述操作流程，並於執行前充分評估風險與備援措施，以確保系統穩定運作。\n\n","categories":["DevOps","Kubernetes"],"tags":["Kubernetes","EKS","RabbitMQ"]},{"title":"Python 列表置頂與排序案例詳解","url":"/blog/cmescd78l00006glcfix1aw1i/","content":"前言本文說明如何用 Python 的 sorted() 和 lambda 實現列表的置頂與排序功能，並搭配範例與運作邏輯說明。\n問題在物件列表排序時，常遇到這兩個需求：\n\n讓指定條件（如 pinned=True）的物件「置頂」\n在置頂及未置頂群組內，依其他屬性（如名稱或建立日期）排序\n\n如何同時達成這兩個目標？以下提供解決方案。\n解決辦法利用 sorted() 的 key 參數，回傳一個元組：\n\n第一元素用於置頂\n第二元素用於群組內排序\n\n範例程式碼class Project:    def __init__(self, name, createDate, pinned):        self.name = name        self.createDate = createDate        self.pinned = pinned    def __repr__(self):        return f&quot;Project(name=&#x27;&#123;self.name&#125;&#x27;, createDate=&#x27;&#123;self.createDate&#125;&#x27;, pinned=&#123;self.pinned&#125;)&quot;projects = [    Project(&quot;專案A&quot;, &quot;2024-06-01&quot;, True),    Project(&quot;專案B&quot;, &quot;2024-05-20&quot;, False),    Project(&quot;專案C&quot;, &quot;2024-06-03&quot;, True),    Project(&quot;專案D&quot;, &quot;2024-05-25&quot;, False),]sortKey = &quot;title&quot;sortScend = &quot;desc&quot;sort_key_map = &#123;&quot;title&quot;: &quot;name&quot;, &quot;newests&quot;: &quot;createDate&quot;&#125;sort_attribute = sort_key_map.get(sortKey, &quot;createDate&quot;)reverse_order = sortScend.lower() == &quot;desc&quot;final_project_list = sorted(    projects,    key=lambda p: (        not p.pinned,        getattr(p, sort_attribute)    ),    reverse=reverse_order)print(final_project_list)\n\n程式碼邏輯說明\nProject 類別：名稱、建立日期、是否置頂\nprojects：物件列表\nsortKey、sortScend：決定排序屬性與方向\nsort_key_map：前端參數與物件屬性對應\nsorted()：\nkey=lambda p: (not p.pinned, getattr(p, sort_attribute))第一個元素讓置頂在前，第二個元素則依指定屬性排序\nreverse=reverse_order控制排序方向（升冪或降冪）\n\n\n\n運作邏輯\n先以 not p.pinned 分群，pinned=True 會排在最前面\n群組內再依選定屬性排序（如名稱、日期）\n排序方向可控制（升冪或降冪）\n\n執行結果範例假設 sortKey = &quot;title&quot; 且 sortScend = &quot;desc&quot;，結果會是：\n[Project(name=&#x27;專案C&#x27;, createDate=&#x27;2024-06-03&#x27;, pinned=True), Project(name=&#x27;專案A&#x27;, createDate=&#x27;2024-06-01&#x27;, pinned=True), Project(name=&#x27;專案D&#x27;, createDate=&#x27;2024-05-25&#x27;, pinned=False), Project(name=&#x27;專案B&#x27;, createDate=&#x27;2024-05-20&#x27;, pinned=False)]\n\n補充\nlambda 是簡潔定義匿名函式的工具\ngetattr() 可動態取得物件屬性\n可根據需求調整排序依據與方式\n\n","categories":["Python"],"tags":["Python","sorted","lambda"]},{"title":"FastAPI 專案設計最佳實踐：Service 分層、Interface 與 Response 包裝","url":"/blog/cmetjpgqd0000nclca340hwo4/","content":"前言在使用 FastAPI 開發專案時，常常會遇到程式碼分層不清、回傳格式不一致，或是測試不易撰寫的問題。本篇文章將整理以下幾個常見問題，並分享如何透過 OOP 思維、抽象依賴 (interface) 與 統一回應格式 來提升程式碼的可讀性、可維護性與擴充性。\n問題\nService 與 API 層耦合  \n\nService 直接回傳 dict 或 BaseResponse，導致難以在 CLI、排程等非 API 場景下重用。\n\n\n回傳格式不一致  \n\n有時回傳 dict，有時回傳 Pydantic Model，導致開發與除錯不方便。\n\n\n測試困難  \n\nAPI 層直接依賴 ProjectService，無法輕易注入假實作 (Fake Service) 進行測試。\n\n\n可讀性不足  \n\nhttpx 請求、錯誤處理、資料模型轉換混雜在同一個函式，程式碼較長且難以維護。\n\n\n\n解決辦法1. 建立抽象介面 (Interface)使用 ABC 定義 IProjectService，讓 API 依賴抽象而非具體實作。這樣可以：  \n\n減少耦合  \n方便替換不同實作 (真實服務 &#x2F; Mock &#x2F; Cached)  \n提升測試可行性\n\nfrom abc import ABC, abstractmethodfrom typing import Listclass IProjectService(ABC):    @abstractmethod    async def create_project(self, user_name: str, request: ProjectCreateRequest) -&gt; ProjectCreateResponse:        ...    @abstractmethod    async def get_project(self, project_id: str, user_name: str) -&gt; ProjectCreateResponse:        ...    @abstractmethod    async def list_projects(self, user_name: str) -&gt; List[ProjectCreateResponse]:        ...\n\n2. Service 專注於業務邏輯Service 負責與外部 API 溝通，並回傳 Domain Model，而不是直接包裝成 API Response。\nclass ProjectService(IProjectService):    async def create_project(self, user_name: str, request: ProjectCreateRequest) -&gt; ProjectCreateResponse:        token = await accountmw_get_jwt_token()        headers = &#123;&quot;Authorization&quot;: f&quot;Bearer &#123;token&#125;&quot;, &quot;Content-Type&quot;: &quot;application/json&quot;&#125;        payload = &#123;&quot;name&quot;: request.name&#125;        async with httpx.AsyncClient() as client:            response = await client.post(PROJECT_API_URL, headers=headers, json=payload)        if response.status_code == 201:            result = response.json().get(&quot;result&quot;, &#123;&#125;)            return ProjectCreateResponse(                id=result.get(&quot;projectId&quot;),                name=result.get(&quot;projectName&quot;),                pinned=result.get(&quot;pinned&quot;, False),                createDate=result.get(&quot;createDate&quot;, timestamp),                updateDate=result.get(&quot;updateDate&quot;, timestamp),            )        else:            error_respone(response)\n\n3. API 層包裝 BaseResponseRouter 的責任是將 Domain Model 轉成 標準回應格式 (BaseResponse)，並定義 response_model。\n@router.post(&quot;/project&quot;, response_model=BaseResponse[ProjectCreateResponse])async def create_project(    request: ProjectCreateRequest,    headers: AuthHeader = Depends(get_auth_headers),    service: IProjectService = Depends(ProjectService)):    project = await service.create_project(headers.x_user_name, request)    return BaseResponse[ProjectCreateResponse](        status=201,        message=&quot;OK&quot;,        result=project    )\n\n這樣分工清楚：\n\nService 專心處理資料\nAPI 統一處理回應格式\n\n4. 測試更容易因為 Router 依賴的是 IProjectService，我們可以替換成假實作：\nclass FakeProjectService(IProjectService):    async def create_project(self, user_name, request):        return ProjectCreateResponse(            id=&quot;fake-123&quot;,            name=request.name,            pinned=False,            createDate=&quot;2025-01-01&quot;,            updateDate=&quot;2025-01-01&quot;        )\n\n在測試時就不用打到真實 API，提高測試速度與穩定性。\n總結\nInterface：提升抽象層次，讓 API 依賴抽象而非實作。\nService：只回傳 Domain Model，專注在商業邏輯。\nRouter：負責統一回應格式，減少耦合。\n測試：可透過 Fake Service 注入，提升測試可維護性。\n\n這樣的設計方式能讓程式碼 簡潔、易讀、可測試，同時符合 物件導向與乾淨架構 (Clean Architecture) 的原則。\n","categories":["Python"],"tags":["Python","FastAPI","OOP","Interface"]}]